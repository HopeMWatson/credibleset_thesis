---
title: "Foundational Definitions and Concepts"
output: pdf_document
---
Defining and understanding key terms:

--In frequentest statistics probability comes into play before collecting data. That is alpha level is predetermined and static. 
95% probability that we will collect data that produces and interval that contains the true parameter. 

--In Bayesian statistics probability comes into play after collecting data. Analysis probability after observing the data. Based on data, now think there is 95% probability that the true parameter is in the interval. 



#credible interval
A credible interval is a range of values within which an unobserved parameter values falls within a particular subjective probability.  (Edwards, 1963) Unlike in frequentist statistics, in Bayesian we are asking what is the likelihood of a hypothesis, given the data we have observed. The data we have observed is represented by both priors - information that was already known that can be incorporated into analysis of the newly observed data. 

#credible set
A credible set is a set of objects, where it is believed one of the objects is the causal variant. Each object is a SNP, that has an assigned posterior probability of being the causal variant. The set is created by setting a threshold, where 

#size of credible set
For one credible set, the size of the credible set is the probability that the credible set contains the causal variant. 

#coverage of credible set
If we repeat analysing a list of credible sets, coverage is the amount of times the causal variant is in that credible set. Here coverage can be defined as number of times the causal variant was in the credible set out of the number of simulations run. This can be expressed as a percentage where if 10 credible sets are analysed and 9 of these credible sets include the causal variant, there is 90% coverage. 

#Posterior Probability 
The statistical probability that a hypothesis is true, calculated in light of relevant observations. Relavant observations may be defined as both the prior information and the new data that is being analysed, both which together generate the posterior probability. For this reason, the posterior probability is proportionally related to the prior, by the expression of the newly observed data. 

#entropy
A measure of a system's disorder. 

#Fine Mapping 
Fine mapping is a process where an entire set of SNPs is refined and narrowed down to a smaller list of SNPs, called a credible set, that is likely to contain the causal variant. 