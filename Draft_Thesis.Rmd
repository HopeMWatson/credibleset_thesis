---
title: "Foundational Definitions and Concepts"
output: pdf_document
---
---
title: "Fine mapping genetic associations"
output: pdf_document
---

# Introduction

Genetic association studies -> find associations.

LD (define) means ...  Problem: which is causal?

## Fine Mapping 
Fine mapping is a process in which researchers try and identify the most likely single or set of variants within which the causal variant should lie.

### lead SNP (smallest p)

### lead SNP + LD friends (eg r2>0.8)

### Bayesian method

Association p values converted to Bayesian posterior probabilities of causality under specific assumptions.  These can be summed over sets of variants to generate a posterior probability a causal variant lies in any given set.

Credible sets - involves sorting

Aims of thesis
- assess Bayesian fine mapping
- hopefully improve it!

Describing this work requires defining and understanding key terms:

--In frequentest statistics probability comes into play before collecting data. That is alpha level is predetermined and static. 
95% probability that we will collect data that produces and interval that contains the true parameter. SAMPLING - MULTIPLE PARALLEL IMAGINARY SAMPLES

--In Bayesian statistics probability comes into play after collecting data. Analysis probability after observing the data. Based on data, now think there is 95% probability that the true parameter is in the interval. BELIEF!

##Posterior Probability 
The Bayesian's belief in a binary hypothesis (eg this SNP is causal vs this SNP is not causal) after seeing the data.  Note difference to prior belief.  Bayes Theoreom

\begin{equation}
\label{eq-Bayes Theorem}
P(X=x|D)
= \frac{P(X=x) P(D|X=x)}{P(D)}
\end{equation}

\begin{equation}
\label{eq-Bayes Theorem}
{P(X=x|D)}
 = \frac{P(D|X=x) P(X=x)}{\sum(P(D|X=y)(P(X=y))}
\end{equation}

\begin{equation}
\label{eq-Bayes Theorem}
{P(X=x|D)}
 \propto {P(D|X=x) P(X=x)}
\end{equation}

statistical probability that a hypothesis is true, calculated in light of relevant observations. Relavant observations may be defined as both the prior information and the new data that is being analysed, both which together generate the posterior probability. For this reason, the posterior probability is proportionally related to the prior, by the expression of the newly observed data. 

##credible interval
A credible interval is a range of values within which an unobserved parameter values falls within a particular subjective probability.  (Edwards, 1963) Unlike in frequentist statistics, in Bayesian we are asking what is the likelihood of a hypothesis, given the data we have observed. The data we have observed is represented by both priors - information that was already known that can be incorporated into analysis of the newly observed data. 

##credible set
A credible set is a set of objects, where it is believed one of the objects is the causal variant. Each object is a SNP, that has an assigned posterior probability of being the causal variant. The set is created by setting a threshold, where 

##size of credible set
For one credible set, the size of the credible set is the belief that the credible set contains the causal variant (eg 90%). 

##coverage of credible set
If we repeat analysing a list of credible sets, coverage is the amount of times the causal variant is in that credible set. Here coverage can be defined as number of times the causal variant was in the credible set out of the number of simulations run. This can be expressed as a percentage where if 10 credible sets are analysed and 9 of these credible sets include the causal variant, there is 90% coverage. 


##entropy
A measure of a system's disorder. 
-sum p log(p)

# Methods

How you did simulations

how you evaluated coverage

how you fixed (if we do!)

# Results

plots of coverage vs size for unordered 'credible sets'

plots of coverage vs size

plots of entropy vs coverage-size

fix!

# Discussion